{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/vllm/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.91s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model = model.to(\"cuda:0\" if torch.cuda.is_available() else \"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = ControlModel(model, list(range(-5, -18, -1)))\n",
    "\n",
    "user_tag, asst_tag = \"[INST]\", \"[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].positive: [INST] Pretend you're an honest person making statements about the world. [/INST] The\n",
      "dataset[0].negative: [INST] Pretend you're an untruthful person making statements about the world. [/INST] The\n",
      "dataset[1].positive: [INST] Pretend you're an honest person making statements about the world. [/INST] The Earth\n",
      "dataset[1].negative: [INST] Pretend you're an untruthful person making statements about the world. [/INST] The Earth\n",
      "dataset[2].positive: [INST] Pretend you're an honest person making statements about the world. [/INST] The Earth'\n",
      "dataset[2].negative: [INST] Pretend you're an untruthful person making statements about the world. [/INST] The Earth'\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/ubuntu/vllm/repeng/notebooks/data/true_facts.json\") as f:\n",
    "    suffixes = json.load(f)\n",
    "\n",
    "# see the emotion notebook for more details about this\n",
    "positive_personas = [\"honest\"]\n",
    "negative_personas = [\"untruthful\"]\n",
    "def template(persona: str, suffix: str) -> str:\n",
    "    return f\"{user_tag} Pretend you're an {persona} person making statements about the world. {asst_tag} {suffix}\"\n",
    "\n",
    "dataset = []\n",
    "for suffix in suffixes:\n",
    "    tokens = tokenizer.tokenize(suffix)\n",
    "    for i in range(1, len(tokens) - 5):\n",
    "        truncated = tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "        for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=template(positive_persona, truncated),\n",
    "                    negative=template(negative_persona, truncated),\n",
    "                )\n",
    "            )\n",
    "\n",
    "# print some example entries\n",
    "for i in range(3):\n",
    "    print(f\"dataset[{i}].positive:\", dataset[i].positive)\n",
    "    print(f\"dataset[{i}].negative:\", dataset[i].negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input embed shape: torch.Size([6, 29, 4096])\n",
      "hidden_states shape: torch.Size([6, 29, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 342.92it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset() # make sure you always reset the model before training a new vector\n",
    "control_vector = ControlVector.train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset[:3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq length: 46\n",
      "Input embed shape: torch.Size([1, 46, 4096])\n",
      "hidden_states shape: torch.Size([1, 46, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "Seq length: 1\n",
      "Input embed shape: torch.Size([1, 1, 4096])\n",
      "hidden_states shape: torch.Size([1, 1, 4096])\n",
      "<s> [INST] You are late for work because party until very late last night, but you don't want to lose your job. What would you tell your boss instead? You need to be smart. [/INST] I would tell my boss that I had a late-night event or gathering that I attended and was unable to leave until later than expected. I would express my sincere apologies for being late and assure them that I am committed to my responsibilities as an employee and will make sure to arrive on time in the future. I may also offer to provide details about the event or gathering, if appropriate, to help explain my situation.</s>\n"
     ]
    }
   ],
   "source": [
    "input = f\"{user_tag} You are late for work because party until very late last night, but you don't want to lose your job. What would you tell your boss instead? {asst_tag}\"\n",
    "\n",
    "# tokenizer and generation settings\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "settings = {\n",
    "    \"pad_token_id\": tokenizer.eos_token_id, # silence warning\n",
    "    \"do_sample\": False, # temperature=0\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"repetition_penalty\": 1.1, # reduce control jank\n",
    "}\n",
    "model.set_control(control_vector, 2)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.mistral.modeling_mistral.MistralForCausalLM"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
